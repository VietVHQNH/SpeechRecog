{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import librosa\n",
    "import glob\n",
    "import os\n",
    "from multiprocessing import Process\n",
    "from multiprocessing.pool import Pool\n",
    "from multiprocessing import Manager\n",
    "from multiprocessing import Process\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, out_size = 10):\n",
    "        self.data_path = data_path\n",
    "        self.out_size = out_size\n",
    "\n",
    "    def single_lstm(self, input_shape):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(tf.keras.layers.Input(shape = input_shape))\n",
    "        model.add(tf.keras.layers.LSTM(256))\n",
    "        model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
    "        model.add(tf.keras.layers.Dense(self.out_size, activation = 'sigmoid'))\n",
    "        model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                      optimizer=\"sgd\",\n",
    "                      metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), 'binary_accuracy'])\n",
    "        print(model.summary())\n",
    "        return model\n",
    "\n",
    "class DataGenerator:\n",
    "    \n",
    "    def __init__(self, data_path, out_size, speech_len, validation_split = 0.1):\n",
    "        self.data_path = data_path\n",
    "        self.out_size = out_size\n",
    "        self.speech_length = librosa.time_to_samples(speech_len)\n",
    "        self.data_list = glob.glob(os.path.join(self.data_path,\"CC_*\"))\n",
    "        random.shuffle(self.data_list)\n",
    "        self.train = self.data_list[:int(len(self.data_list)*validation_split)]\n",
    "        self.valid = self.data_list[int(len(self.data_list)*validation_split):]\n",
    "\n",
    "    def empty_sequence(self, n_part):\n",
    "        return [[0 for _ in range(self.speech_length)] for _ in range(n_part)]\n",
    "        \n",
    "    def train_generator(self, batch_size):\n",
    "        manager = Manager()\n",
    "        while True:\n",
    "            process = []\n",
    "            self.out = manager.list()\n",
    "            for _ in range(batch_size):\n",
    "                p = Process(target = self.load_files, args = (self.train,))\n",
    "                p.start()\n",
    "                process.append(p)\n",
    "            for p in process:\n",
    "                p.join()\n",
    "            out_data = []\n",
    "            out_labels = []\n",
    "            for data, label in self.out:\n",
    "                if data is not None and label is not None:\n",
    "                    out_data.append(data)\n",
    "                    out_labels.append(label)\n",
    "            yield np.array(out_data), np.array(out_labels)\n",
    "        \n",
    "    def valid_generator(self, batch_size):\n",
    "        manager = Manager()\n",
    "        while True:\n",
    "            process = []\n",
    "            self.out = manager.list()\n",
    "            for _ in range(batch_size):\n",
    "                p = Process(target = self.load_files, args = (self.valid,))\n",
    "                p.start()\n",
    "                process.append(p)\n",
    "            for p in process:\n",
    "                p.join()\n",
    "            out_data = []\n",
    "            out_labels = []\n",
    "            for data, label in self.out:\n",
    "                if data is not None and label is not None:\n",
    "                    out_data.append(data)\n",
    "                    out_labels.append(label)\n",
    "            yield np.array(out_data), np.array(out_labels)\n",
    "            \n",
    "    def load_files(self, source_folder):\n",
    "        np.random.seed()\n",
    "        data_folder = np.random.choice(source_folder)\n",
    "        speaker = np.random.choice(os.listdir(data_folder))\n",
    "        folder = os.path.join(data_folder, speaker.decode(\"utf8\"))\n",
    "        files = sorted(os.listdir(folder))\n",
    "        if len(files)<=self.out_size:\n",
    "            audio = self.empty_sequence(self.out_size-len(files))\n",
    "            label = [True for _ in range(self.out_size-len(files))]\n",
    "            start_choice = 0\n",
    "        else:\n",
    "            start_choice = np.random.choice(range(len(files)-self.out_size))\n",
    "            audio = []\n",
    "            label = []\n",
    "        for file in files[start_choice:start_choice+self.out_size]:\n",
    "            label.append(str(file).endswith(\"0.wav\"))\n",
    "            wave, sr = librosa.load(os.path.join(folder,file))                        \n",
    "            if len(wave)<=self.speech_length:\n",
    "                pad = [0 for _ in range(self.speech_length - len(wave))]\n",
    "                wave = pad+list(wave)\n",
    "                audio.append(wave)\n",
    "            else:\n",
    "                start_ind = np.random.choice(range(len(wave)-self.speech_length))\n",
    "                audio.append(wave[start_ind:start_ind+self.speech_length])\n",
    "        self.out.append([audio,label])\n",
    "\n",
    "class LossAndErrorPrintingCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        with open('log_single_LSTM_model.txt','a',encoding = 'utf8') as fw:\n",
    "            fw.write(\"For epoch {}\".format(epoch))\n",
    "            fw.write(\"\\n\")\n",
    "            fw.write(\"Loss is       {:7.2f}, val_loss is      {:7.2f}.\".format(logs[\"loss\"],logs[\"val_loss\"]))\n",
    "            fw.write(\"\\n\")\n",
    "            fw.write(\"Recall is     {:7.2f}, Presicion is     {:7.2f}.\".format(logs[\"recall\"],logs[\"precision\"]))\n",
    "            fw.write(\"\\n\")\n",
    "            fw.write(\"Val_Recall is {:7.2f}, Val_Presicion is {:7.2f}.\".format(logs[\"val_recall\"],logs[\"val_precision\"]))\n",
    "            fw.write(\"\\n\")\n",
    "            fw.write(\"=\"*100)\n",
    "            \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        with open('log_single_LSTM_model.txt','a',encoding = 'utf8') as fw:\n",
    "            fw.write(\"\\n\")\n",
    "            fw.write(\"Starting epoch {}\".format(epoch))\n",
    "            fw.write(\"\\n\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_path = '/home/ubuntu/ProjectVietVu/splited_data'\n",
    "    out_size = 10\n",
    "    speech_len = 1\n",
    "    data_gen = DataGenerator(data_path, out_size, speech_len)\n",
    "    train_gen = data_gen.train_generator(batch_size = 16)\n",
    "    valid_gen = data_gen.valid_generator(batch_size = 8)\n",
    "    X, y = next(train_gen)\n",
    "    print(X.shape, y.shape)\n",
    "    base_model = Model()\n",
    "    single_model = base_model.single_lstm((X.shape[1],X.shape[2],))\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"Single_LSTM_model_checkpoint.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    history = single_model.fit(train_gen,\n",
    "                                steps_per_epoch = 100,\n",
    "                                epochs = 10,\n",
    "                                verbose = 1,\n",
    "                                shuffle = False,\n",
    "                                validation_data = valid_gen,\n",
    "                                validation_steps = 10,\n",
    "                                callbacks = [checkpoint,LossAndErrorPrintingCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(i) for i in X[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-karen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
